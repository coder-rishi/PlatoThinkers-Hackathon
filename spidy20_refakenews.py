{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:48.800929Z\",\"iopub.execute_input\":\"2021-09-12T10:07:48.801578Z\",\"iopub.status.idle\":\"2021-09-12T10:07:48.812952Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:48.801539Z\",\"shell.execute_reply\":\"2021-09-12T10:07:48.811786Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n            \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:48.815136Z\",\"iopub.execute_input\":\"2021-09-12T10:07:48.816462Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.160403Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:48.816410Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.159390Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport pandas as pd\ntrue_df = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\nfake_df = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.161928Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.162250Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.169064Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.162215Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.168016Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ntrue_df['label'] = 0\nfake_df['label'] = 1\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.172063Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.172862Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.187293Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.172815Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.186259Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset = pd.concat([true_df , fake_df])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.188807Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.189106Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.201373Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.189076Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.200408Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset = dataset[['text','label']]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.203013Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.203294Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.214965Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.203260Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.214108Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.216263Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.216516Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.236629Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.216487Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.234854Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset = dataset.sample(frac=1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.238183Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.239295Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.255663Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.239244Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.253335Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndataset.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.257407Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.258181Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.268529Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.258115Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.267555Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nx = dataset['text']\ny = dataset['label']\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.272254Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.273172Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.286055Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.273123Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.284976Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nx\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.287401Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.287633Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.301118Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.287606Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.299513Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ny\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.303193Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.303524Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.313409Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.303483Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.312069Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:07:50.315335Z\",\"iopub.execute_input\":\"2021-09-12T10:07:50.315671Z\",\"iopub.status.idle\":\"2021-09-12T10:07:50.352474Z\",\"shell.execute_reply.started\":\"2021-09-12T10:07:50.315631Z\",\"shell.execute_reply\":\"2021-09-12T10:07:50.351386Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nx_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=0)\nx_train\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:14:38.886054Z\",\"iopub.execute_input\":\"2021-09-12T10:14:38.886355Z\",\"iopub.status.idle\":\"2021-09-12T10:14:58.954126Z\",\"shell.execute_reply.started\":\"2021-09-12T10:14:38.886325Z\",\"shell.execute_reply\":\"2021-09-12T10:14:58.953393Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ntfvect = TfidfVectorizer(stop_words='english', max_df=0.7)\ntfid_x_train = tfvect.fit_transform(x_train)\ntfid_x_test = tfvect.transform(x_test)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:15:01.530945Z\",\"iopub.execute_input\":\"2021-09-12T10:15:01.531366Z\",\"iopub.status.idle\":\"2021-09-12T10:15:02.031561Z\",\"shell.execute_reply.started\":\"2021-09-12T10:15:01.531335Z\",\"shell.execute_reply\":\"2021-09-12T10:15:02.030437Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nclassifier = PassiveAggressiveClassifier(max_iter=50)\nclassifier.fit(tfid_x_train, y_train)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:15:15.851785Z\",\"iopub.execute_input\":\"2021-09-12T10:15:15.852125Z\",\"iopub.status.idle\":\"2021-09-12T10:15:15.866039Z\",\"shell.execute_reply.started\":\"2021-09-12T10:15:15.852094Z\",\"shell.execute_reply\":\"2021-09-12T10:15:15.865276Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ny_pred = classifier.predict(tfid_x_test)\nscore = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {round(score*100, 9)}%')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:24:57.836884Z\",\"iopub.execute_input\":\"2021-09-12T10:24:57.837315Z\",\"iopub.status.idle\":\"2021-09-12T10:24:57.855338Z\",\"shell.execute_reply.started\":\"2021-09-12T10:24:57.837274Z\",\"shell.execute_reply\":\"2021-09-12T10:24:57.854644Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ncf = confusion_matrix(y_test, y_pred, labels =[1, 0])\nprint(cf)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:32:07.559157Z\",\"iopub.execute_input\":\"2021-09-12T10:32:07.559518Z\",\"iopub.status.idle\":\"2021-09-12T10:32:07.568970Z\",\"shell.execute_reply.started\":\"2021-09-12T10:32:07.559470Z\",\"shell.execute_reply\":\"2021-09-12T10:32:07.567816Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ndef fake_news_det(news):\n    input_data=[news]\n    vectorized_input_data = tfvect.transform(input_data)\n    prediction = classifier.predict(vectorized_input_data)\n    print(prediction)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2021-09-12T10:44:56.472405Z\",\"iopub.execute_input\":\"2021-09-12T10:44:56.472753Z\",\"iopub.status.idle\":\"2021-09-12T10:44:56.479072Z\",\"shell.execute_reply.started\":\"2021-09-12T10:44:56.472708Z\",\"shell.execute_reply\":\"2021-09-12T10:44:56.478405Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport pickle\npickle.dump(classifier, open('model.pkl', 'wb'))\n\n# that's it, guys! we now have a model.pkl file.","metadata":{"_uuid":"3bc79094-1b02-457f-888c-63159d1b800f","_cell_guid":"3966dcce-6e2a-4cad-a494-67a4309e9c36","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}